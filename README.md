# DatasetGenPipeline
è¾“å…¥ä¸€æ®µç¬¬ä¸€äººç§°è§†è§’æ‹æ‘„çš„çŸ­è§†é¢‘ï¼ˆ2minå·¦å³ï¼‰ï¼Œè½¨è¿¹å’Œæ‰€è§çš„ç‰©ä½“æ˜ å°„åˆ°2Dåœ°å›¾ä¸Šï¼Œç”Ÿæˆä¸€å¼  local map

![local map](dataset/photos/Waikiki_0000_map.jpg)

## é¡¹ç›®ç®€ä»‹

æœ¬é¡¹ç›®å®ç°äº†ä¸€ä¸ªåŸºäºç¬¬ä¸€äººç§°æ‹æ‘„è§†é¢‘çš„ **å±€éƒ¨åœ°å›¾ (local map) æ„å»ºç®¡é“**ã€‚
é€šè¿‡æ•´åˆ **COLMAPã€DPVOã€Grounded-SAM-2ã€Metric3D** ç­‰å·¥å…·ï¼Œå¯ä»¥è‡ªåŠ¨å®Œæˆï¼š

1. **ç›¸æœºå†…å‚ä¼°è®¡**ï¼ˆä½¿ç”¨ COLMAPï¼‰ã€‚
2. **ç›¸æœºè½¨è¿¹ä¼°è®¡**ï¼ˆä½¿ç”¨ DPVOï¼‰ã€‚
3. **ç‰©ä½“æ£€æµ‹ä¸åˆ†å‰²**ï¼ˆä½¿ç”¨ Grounded-SAM-2 + Grounding DINOï¼‰ã€‚
4. **æ·±åº¦ä¼°è®¡ä¸ç‚¹äº‘é‡å»º**ï¼ˆä½¿ç”¨ Metric3Dï¼‰ã€‚
5. **è½¨è¿¹ä¸ç‚¹äº‘çš„å°ºåº¦å¯¹é½**ï¼ˆé€šè¿‡ DPVO ç‚¹äº‘ä¸ Metric3D ç‚¹äº‘çš„åŒ¹é…ï¼‰ã€‚
6. **ç‰©ä½“åæ ‡ä»ç›¸æœºç³»è½¬æ¢åˆ°ä¸–ç•Œç³»**ã€‚
7. **ç”Ÿæˆ Local Map**ï¼ˆåŒ…å«ç›¸æœºè½¨è¿¹ä¸æ£€æµ‹åˆ°çš„ç‰©ä½“ä½ç½®ï¼‰ã€‚

## ä½¿ç”¨æ–¹æ³•

### è¿è¡Œä¸»å…¥å£

è°ƒç”¨ `CombinedPipeline.process_video` æ¥å¤„ç†è§†é¢‘ï¼š

```python
from pipeline import CombinedPipeline

pipeline = CombinedPipeline()

# è®¾ç½®æ¨¡å‹è·¯å¾„
pipeline.set_model_paths(
    sam2_checkpoint="path/to/sam2_ckpt.pth",
    model_cfg="path/to/sam2_cfg.yaml",
    grounding_dino_config="path/to/grounding_dino_cfg.py",
    grounding_dino_checkpoint="path/to/grounding_dino_ckpt.pth",
    metric3d_config="path/to/metric3d_cfg.py",
    metric3d_ckpt="path/to/metric3d_ckpt.pth"
)

# è¿è¡Œè§†é¢‘å¤„ç†
output_video = pipeline.process_video(
    video_path="your_video.mp4",
    text_prompt="chair, table, person",  # éœ€è¦æ£€æµ‹çš„ç±»åˆ«
    output_dir="./outputs",
    max_seconds=30,
    frames_per_second=2.0,
    colmap_interval=2.0,
    need_run_dpvo=True,
    max_distance=7.0
)
```

è¿è¡Œåå°†ç”Ÿæˆï¼š

* **å¤„ç†åçš„è§†é¢‘**ï¼ˆå¸¦æ£€æµ‹æ¡†å’Œåˆ†å‰²ç»“æœï¼‰
* **å¯è§†åŒ–çš„ local map**
* **å›¾åƒmaskã€æ·±åº¦å›¾ã€è½¨è¿¹æ–‡ä»¶ç­‰ç­‰ä¸­é—´ç”Ÿæˆç‰©**


## ä»£ç æµç¨‹

### 1. ç›¸æœºå†…å‚è®¡ç®—ï¼ˆ`_compute_average_focal_lengths`ï¼‰

* ä»è§†é¢‘ä¸­æŒ‰é—´éš”æŠ½å¸§ã€‚
* ä½¿ç”¨ COLMAP è¿›è¡Œç‰¹å¾æå–ã€åŒ¹é…å’Œå¢é‡é‡å»ºã€‚
* å¾—åˆ°ç„¦è·å‚æ•° `fx, fy` å’Œå›¾åƒä¸­å¿ƒç‚¹ `cx, cy`ã€‚
* å†™å…¥ `intrinsic.txt` ä¸ DPVO çš„ `camera.txt`ã€‚

### 2. ç›¸æœºè½¨è¿¹ä¼°è®¡ï¼ˆ`run_dpvo`ï¼‰

* ä½¿ç”¨ DPVO ä»è§†é¢‘å¸§ä¸­æ¢å¤ç›¸æœºä½å§¿ã€‚
* è¾“å‡ºè½¨è¿¹æ–‡ä»¶ï¼ˆTUM æ ¼å¼ï¼‰ã€è½¨è¿¹å›¾ã€ç‚¹äº‘æ–‡ä»¶ã€‚
* ç‚¹äº‘ä¿å­˜ä¸º `.ply`ã€‚

### 3. æ¨¡å‹åˆå§‹åŒ–ï¼ˆ`initialize_models`ï¼‰

* åˆå§‹åŒ– **SAM2 è§†é¢‘é¢„æµ‹å™¨**ã€**Grounding DINO**ã€**Metric3D**ã€‚
* ä¸åŒæ¨¡å‹æ ¹æ®æ˜¾å­˜æƒ…å†µé€‰æ‹©æ··åˆç²¾åº¦æˆ– FP32ã€‚

### 4. ç‰©ä½“æ£€æµ‹ä¸è·Ÿè¸ªï¼ˆ`_process_frame_batch`ï¼‰

* ä½¿ç”¨ Grounding DINO æ ¹æ®æ–‡æœ¬æç¤ºæ£€æµ‹ç›®æ ‡ã€‚
* ä½¿ç”¨ SAM2 å¯¹ç›®æ ‡åšç²¾ç»†åˆ†å‰²å¹¶è·¨å¸§ä¼ æ’­ã€‚
* ä¿å­˜ maskï¼ˆ`.npy`ï¼‰ã€JSON å…ƒæ•°æ®ã€å¯è§†åŒ–ç»“æœã€‚

### 5. æ·±åº¦ä¼°è®¡ï¼ˆ`_initialize_metric3d` + `do_scalecano_test_with_custom_data_my_designed`ï¼‰

* ä½¿ç”¨ Metric3D ä¼°è®¡æ·±åº¦å›¾ã€‚
* è¾“å‡º `.npy` æ·±åº¦æ–‡ä»¶ã€`.ply` ç‚¹äº‘æ–‡ä»¶ã€‚

### 6. å°ºåº¦å¯¹é½ï¼ˆ`align_scale_with_metric3d`ï¼‰

* å°† DPVO ç‚¹äº‘æŠ•å½±åˆ°ç›¸æœºå¹³é¢ã€‚
* ä¸ Metric3D æ·±åº¦ç‚¹äº‘è¿›è¡ŒåŒ¹é…ã€‚
* ä½¿ç”¨ RANSAC æ‹Ÿåˆ **å…¨å±€å°ºåº¦å› å­**ã€‚
* ä¿®æ­£è½¨è¿¹ä¸ç‚¹äº‘çš„ç»å¯¹å°ºåº¦ã€‚

### 7. ç”Ÿæˆ Local Mapï¼ˆ`_generate_local_map` / `generate_visualization`ï¼‰

* ç»˜åˆ¶ç›¸æœºè½¨è¿¹ï¼ˆè“çº¿ + æ¸å˜ç‚¹ï¼‰ã€‚
* æ ‡è®°èµ·ç‚¹å’Œç»ˆç‚¹ã€‚
* å°†æ£€æµ‹åˆ°çš„ç‰©ä½“åœ¨ä¸–ç•Œåæ ‡ç³»ä¸­ç»˜åˆ¶åˆ°åœ°å›¾ã€‚
* è¾“å‡º `local_map.jpg`ã€‚

## ä¸»è¦å‡½æ•°è¯´æ˜

### ç±»ï¼š`CombinedPipeline`

é¡¹ç›®çš„æ ¸å¿ƒç±»ï¼Œè´Ÿè´£ç»„ç»‡æ•´ä¸ªæµç¨‹ã€‚

#### è®¾ç½®ä¸åˆå§‹åŒ–

* `set_model_paths(...)`ï¼šè®¾ç½®æ¨¡å‹è·¯å¾„ã€‚
* `initialize_models(...)`ï¼šåŠ è½½æ‰€æœ‰æ¨¡å‹ã€‚
* `_initialize_metric3d(...)`ï¼šåŠ è½½ Metric3Dã€‚

#### ç›¸æœºä¸è½¨è¿¹

* `_compute_average_focal_lengths(video_path, colmap_interval)`ï¼šCOLMAP ä¼°è®¡ç„¦è·ã€‚
* `_get_first_frame_dimensions(frames_dir)`ï¼šè¯»å–å›¾åƒå°ºå¯¸å’Œä¸­å¿ƒç‚¹ã€‚
* `_create_dpvo_calibration_file(video_output_dir)`ï¼šç”Ÿæˆ DPVO æ‰€éœ€çš„ `camera.txt`ã€‚
* `run_dpvo(...)`ï¼šè¿è¡Œ DPVO è·å–è½¨è¿¹ä¸ç‚¹äº‘ã€‚

#### å°ºåº¦ä¸ä½å§¿

* `align_scale_with_metric3d(...)`ï¼šä½¿ç”¨ Metric3D ç‚¹äº‘å¯¹é½ DPVO è½¨è¿¹ã€‚
* `_apply_scale_to_poses(scale)`ï¼šåº”ç”¨å°ºåº¦åˆ°ä½å§¿ã€‚
* `_apply_scale_to_point_cloud(scale)`ï¼šåº”ç”¨å°ºåº¦åˆ°ç‚¹äº‘ã€‚
* `_save_scaled_trajectory(file, scale)`ï¼šä¿å­˜å°ºåº¦ä¿®æ­£åçš„è½¨è¿¹ã€‚

#### ç‰©ä½“æ£€æµ‹ä¸è·Ÿè¸ª

* `_process_frame_batch(...)`ï¼šå•æ‰¹å¸§çš„ç‰©ä½“æ£€æµ‹ä¸ mask ä¼ æ’­ã€‚
* `_propagate_and_save_masks(...)`ï¼šmask ä¼ æ’­ã€‚
* `_save_mask_and_json(...)`ï¼šä¿å­˜ mask å’Œ JSONã€‚
* `_draw_masks_with_position(...)`ï¼šè®¡ç®—ç‰©ä½“åœ¨ä¸–ç•Œåæ ‡ä¸­çš„ä½ç½®ã€‚

#### å¯è§†åŒ–ä¸ç»“æœ

* `_generate_local_map(output_dir, object_positions)`ï¼šç”Ÿæˆå±€éƒ¨åœ°å›¾ã€‚
* `generate_visualization(...)`ï¼šè½¨è¿¹ + ç‰©ä½“å¯è§†åŒ–ã€‚
* `process_video(...)`ï¼šä¸»å…¥å£ï¼Œæ•´åˆæ‰€æœ‰æ­¥éª¤ã€‚

## è¾“å‡ºç»“æœç›®å½•ç»“æ„

å¤„ç†å®Œæˆåï¼Œ`output_dir` ä¸‹ä¼šåŒ…å«ä»¥ä¸‹ç»“æ„ï¼š

```
outputs/
  result_dir/
    output_video/        # å¤„ç†åçš„è§†é¢‘
    local_map/           # local map å¯è§†åŒ–å›¾
  yourvideo_xxx/
    frames/              # æŠ½å–çš„å¸§
    dpvo/                # DPVOç»“æœï¼ˆè½¨è¿¹ã€ç‚¹äº‘ã€colmapæ–‡ä»¶ï¼‰
    colmap/              # ç›¸æœºå†…å‚æ–‡ä»¶
    mask_data/           # SAM2ç”Ÿæˆçš„mask
    json_data/           # ç‰©ä½“ä¿¡æ¯json
    depth_data/          # Metric3Dæ·±åº¦ç‚¹äº‘
    result/              # å¸¦å¯è§†åŒ–ç»“æœçš„å¸§
    mask_photo/          # maskæ¸²æŸ“å›¾
    depth_photo/         # æ·±åº¦æ¸²æŸ“å›¾
```


## ç¯å¢ƒéƒ¨ç½²
#### PSï¼š
> ç›¸å…³å¼€æºé¡¹ç›®çš„ git clone å·²ç»æ”¾å…¥è¿™ä¸ªé¡¹ç›®äº†ï¼Œå¿…è¦çš„æƒé‡æ•°æ®ä¹Ÿå·²æ”¾åœ¨å¯¹äºä½ç½®ã€‚æ‰€ä»¥åªéœ€è¦æŒ‰ä¸‹é¢æ­¥éª¤é…ç½®å¥½ conda ç¯å¢ƒä¸­çš„ä¾èµ–å°±å¯ä»¥äº†ï¼Œä¸ç”¨å…‹éš†å…¶ä»–ä»“åº“å’Œä¸‹è½½å…¶ä»–æƒé‡èµ„æºã€‚
### å…‹éš† DatasetGenPipeline
```
git clone https://github.com/HowLegend/DatasetGenPipeline.git
cd DatasetGenPipeline

```
### åˆ›å»º conda ç¯å¢ƒ
ä½¿ç”¨ python=3.10 ä»¥åŠ torch >= 2.3.1ã€torchvision>=0.18.1 å’Œ cuda-12.1 ä»¥ä¸Š

æ ¹æ®è‡ªå·±ç¯å¢ƒæ¥å®‰è£…ç‰¹å®šçš„ conda ç¯å¢ƒ

```
conda create -n dgp python=3.10 -y
conda activate dgp
pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu124
```

### éƒ¨ç½² Grounded-SAM-2
```
git clone https://github.com/IDEA-Research/Grounded-SAM-2.git
```
ä¸‹è½½ Segment Anything 2 æƒé‡
```
cd Grounded-SAM-2
cd checkpoints
bash download_ckpts.sh
cd ..
```
ä¸‹è½½ Grounding DINO æƒé‡
```
cd gdino_checkpoints
bash download_ckpts.sh
cd ..
```
å®‰è£… Segment Anything 2
```
pip install -e .
```
å®‰è£… Grounding DINO
```
pip install --no-build-isolation -e grounding_dino
```
è¿”å›ä¸»ç›®å½• DatasetGenPipeline
```
cd ..
```
### éƒ¨ç½² Metric3D
```
git clone https://github.com/YvanYin/Metric3D.git
cd Metric3D
```
è¿™é‡Œé€‰ç”¨çš„æ˜¯ Metric3D çš„ ViT æ¨¡å‹ï¼ŒåŸé¡¹ç›®ä¸­çš„ requirements_v2.txt ä¼šç ´åç°æœ‰ç¯å¢ƒï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨è¿™é‡Œå‡†å¤‡çš„ DatasetGenPipeline/requirements_Metric3D.txt
```
# åœ¨ä¸»ç›®å½• DatasetGenPipeline ä¸‹
pip install -r requirements_Metric3D.txt
```
#### ä¸‹è½½æƒé‡æ–‡ä»¶ 
|      |       Encoder       |      Decoder      |                                               Link                                                |
|:----:|:-------------------:|:-----------------:|:-------------------------------------------------------------------------------------------------:|
| v1-T |    ConvNeXt-Tiny    | Hourglass-Decoder | [Download ğŸ¤—](https://huggingface.co/JUGGHM/Metric3D/blob/main/convtiny_hourglass_v1.pth)        |
| v1-L |   ConvNeXt-Large    | Hourglass-Decoder | [Download](https://drive.google.com/file/d/1KVINiBkVpJylx_6z1lAC7CQ4kmn-RJRN/view?usp=drive_link) |
| v2-S | DINO2reg-ViT-Small  |    RAFT-4iter     | [Download](https://drive.google.com/file/d/1YfmvXwpWmhLg3jSxnhT7LvY0yawlXcr_/view?usp=drive_link) |
| v2-L | DINO2reg-ViT-Large  |    RAFT-8iter     | [Download](https://drive.google.com/file/d/1eT2gG-kwsVzNy5nJrbm4KC-9DbNKyLnr/view?usp=drive_link) |
| v2-g | DINO2reg-ViT-giant2 |    RAFT-8iter     | [Download ğŸ¤—](https://huggingface.co/JUGGHM/Metric3D/blob/main/metric_depth_vit_giant2_800k.pth) | 

è¿™é‡Œæˆ‘ä»¬ä¸‹è½½ v2-L ç‰ˆæœ¬
```
cd Metric3D/weight
gdown 1eT2gG-kwsVzNy5nJrbm4KC-9DbNKyLnr
cd ..
```
è¿”å›ä¸»ç›®å½• DatasetGenPipeline
```
cd ..
```
### éƒ¨ç½² DPVO
```
git clone https://github.com/princeton-vl/DPVO.git --recursive
cd DPVO
```
å®‰è£… DPVO ä¾èµ–

> è™½ç„¶ PyTorch å®˜æ–¹æä¾›äº† cu124 çš„ wheelï¼Œä½† PyTorch Geometricï¼ˆtorch-scatter çš„å®˜æ–¹å‘å¸ƒæ–¹ï¼‰å°šæœªä¸º cu124 æä¾›é¢„ç¼–è¯‘åŒ…ã€‚
>
> ä¸è¿‡ï¼ŒCUDA æ˜¯å‘åå…¼å®¹çš„ â€”â€” å¯ä»¥å®‰å…¨åœ°å®‰è£…ä¸º cu121 ç¼–è¯‘çš„ torch-scatterï¼Œå®ƒä¹Ÿä¼šåœ¨ CUDA 12.4 ç³»ç»Ÿä¸Šå®Œç¾è¿è¡Œ
```
# å®‰è£… torch-scatter åŒ…
pip install torch-scatter -f https://data.pyg.org/whl/torch-2.5.1+cu121.html

# å®‰è£…å…¶ä»– pip åŒ…
pip install tensorboard numba tqdm einops pypose kornia numpy plyfile evo opencv-python yacs
```
### ä¸‹è½½ DPVO èµ„æºåŒ…
```
wget https://gitlab.com/libeigen/eigen/-/archive/3.4.0/eigen-3.4.0.zip
unzip eigen-3.4.0.zip -d thirdparty

# install DPVO
pip install .

# download models and data (~2GB)
./download_models_and_data.sh
```
è¿”å›ä¸»ç›®å½• DatasetGenPipeline
```
cd ..
```
### ä¸‹è½½è¡¥å…… pip åŒ…
```
pip install supervision pycolmap scikit-learn transformers pycocotools
```
